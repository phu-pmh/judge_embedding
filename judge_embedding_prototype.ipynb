{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcde4a0a930>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Phu, Andrea and Watcher\n",
    "# 2018 Spring\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import FloatTensor, LongTensor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "import torch.utils.data as data_utils\n",
    "import psutil\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_current_memory_usage():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    mem_use_in_GB = py.memory_info().rss/(2**30)\n",
    "    print(\"currently using\",mem_use_in_GB,\"GB memory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1.post2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# make sure you have the nltk resource downloaded\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    print(\"no nltk resource, downloading now\")\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify data paths for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data paths, so we can read data easily\n",
    "ruling_data_path = '/data/Dropbox/Projects/originalism/data/BloombergVOTELEVEL_Touse.dta'\n",
    "sentences_data_path = '/data/Dropbox/judge_embedding_data_sp18/sentences_data.csv'\n",
    "cite_graph_path = '/data/Dropbox/Data/corpora/chen-cases/cite-graph/graph.zip'\n",
    "judge_bio_data_path = '/data/Dropbox/Data/Judge-Bios/judgebios/JudgesBioReshaped_TOUSE.dta'\n",
    "topic_data_path = '/data/Dropbox/Projects/Ash_Chen/metadata/bb2topic.pkl'\n",
    "processed_data_path = '/data/Dropbox/judge_embedding_data_sp18'\n",
    "\n",
    "merged_sentence_data_path = '/data/Dropbox/judge_embedding_data_sp18/sentence_topic_judgeid.csv'\n",
    "\n",
    "meta_data_path = '/data/Dropbox/judge_embedding_data_sp18/circuit_metadata_excerpt.dta'\n",
    "table_of_cases_path = '/data/Dropbox/judge_embedding_data_sp18/tableofcases'\n",
    "\n",
    "judge_mapping_binary_filename = 'judgemap.pkl'\n",
    "\n",
    "# currently using 6B 300d glove, this one has 400K vocab\n",
    "glove_emb_path = '/data/Dropbox/judge_embedding_data_sp18/glove_files/glove.6B.300d.txt'\n",
    "glove_binary_filename = 'glove6B300d.pkl'\n",
    "\n",
    "opinion_sum_vector_final_merged_data_filename = 'opinion_sum_vec_final.pkl'\n",
    "opinion_sum_vector_split_6_data_filename = '/data/Dropbox/judge_embedding_data_sp18/opinion_sum_vec_split6.pkl'\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first, read in the GloVe embeddings. If you did the processing already and have the glove binary, just read the binary it's faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_glove_emb(glove_emb_path,verbose=0):\n",
    "    # ONLY DO THIS IF YOU HAVEN'T DONE IT\n",
    "    # this function takes the path to glove embedding txt file,\n",
    "    # and give back 3 things:\n",
    "    # the embedding in numpy matrix form\n",
    "    # the word to index dictionary\n",
    "    # the index to word dictionary\n",
    "    \n",
    "    starttime = time.time()\n",
    "    # first open file\n",
    "    glove_fpt = open(glove_emb_path,\"r\")\n",
    "    # get first line\n",
    "    line = glove_fpt.readline()\n",
    "    word_index = 0\n",
    "    list_of_vectors = []\n",
    "    word2index = {} # this is used for converting word into an index\n",
    "    index2word = {} # \n",
    "    while line:\n",
    "#         if word_index == 1000: # DEBUGGING ONLY\n",
    "#             break\n",
    "        \n",
    "        # print debugging info if verbose\n",
    "        \n",
    "        if verbose and word_index % 10000 == 0:\n",
    "            print(word_index,time.time()-starttime)\n",
    "        \n",
    "        line = line.split()\n",
    "        word = line[0]\n",
    "        word2index[word] = word_index # here count \n",
    "        index2word[word_index] = word\n",
    "        \n",
    "        vector = [float(num) for num in line[1:]]\n",
    "        list_of_vectors.append(vector)\n",
    "        \n",
    "        line = glove_fpt.readline()\n",
    "        word_index += 1  \n",
    "        \n",
    "    emb_matrix = np.array(list_of_vectors)\n",
    "    return emb_matrix, word2index, index2word\n",
    "    \n",
    "# glove_emb, word2index, index2word = get_glove_emb(glove_emb_path,verbose=1) # run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_glove_to_binary_file(glove_emb, word2index, index2word,processed_data_path,save_filename):\n",
    "    # use this to dump processed glove embedding to binary for faster use later\n",
    "    # file name relative to processed data path\n",
    "    with open(os.path.join(processed_data_path,save_filename),\"wb\") as f:  \n",
    "        pickle.dump([glove_emb, word2index, index2word], f)\n",
    "\n",
    "# dump_glove_to_binary_file(glove_emb, word2index, index2word,\"glove6B300d.pkl\") # run this once\n",
    "\n",
    "def load_glove_binary(processed_data_path,save_filename):\n",
    "    # after processed and saved glove binary, each time we use it we just load from the binary\n",
    "    # file name relative to processed data path\n",
    "    with open(os.path.join(processed_data_path,save_filename),\"rb\") as f:  \n",
    "        glove_emb, word2index, index2word = pickle.load(f) \n",
    "    return glove_emb, word2index, index2word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_emb, word2index, index2word = load_glove_binary(processed_data_path,glove_binary_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13075"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index[\"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word[13075]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we have the glove embeddings, we can convert an opinion text into a vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_merged_sentence_data(merged_sentence_data_path):\n",
    "    # read merged sentence data, which should be in a csv file, use pandas\n",
    "    merged_sentence_data = pd.read_csv(merged_sentence_data_path)\n",
    "    return merged_sentence_data\n",
    "    \n",
    "merged_sentence_data_df = read_merged_sentence_data(merged_sentence_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentence_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_INDEX = 400000\n",
    "\n",
    "def clean_sentence(sentence,delete_punc_table,word2index,unknown_index):\n",
    "    # for each opinion text, we use this function to clean it up\n",
    "    # first the punctuations are removed\n",
    "    # then we tokenize it using nltk\n",
    "    # then the first 10 words are removed because they might contain judge's name\n",
    "    # and we don't want that in our data\n",
    "    \n",
    "    # then we will convert each word to an index\n",
    "    # in our case this index dict comes from GloVe\n",
    "    \n",
    "    # define the table elsewhere so you don't define it everytime\n",
    "    # delete_punc_table= str.maketrans(\"\",\"\",string.punctuation)\n",
    "    sentence = sentence.translate(delete_punc_table) # remove punctuations\n",
    "    tokens = nltk.word_tokenize(sentence) # tokenize\n",
    "    tokens = tokens[10:] #remove first 10 words\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in word2index:\n",
    "            tokens[i] = word2index[tokens[i]]\n",
    "        else:\n",
    "            tokens[i] = unknown_index\n",
    "    return tokens\n",
    "    \n",
    "def clean_all_sentences_in_merged(merged_df,word2index,UNKNOWN_INDEX,verbose=0):\n",
    "    starttime = time.time()\n",
    "    # this function takes in merged sentence data and changes \n",
    "    # all the opinion text to cleaned, list of index version\n",
    "    n_entry = merged_df.shape[0]\n",
    "    delete_punc_table= str.maketrans(\"\",\"\",string.punctuation)\n",
    "    for i in range(n_entry):\n",
    "        if verbose and i%10000==0:\n",
    "            print(i,time.time()-starttime)\n",
    "        \n",
    "        sentence = merged_df.loc[i,'opinion_text']\n",
    "\n",
    "        if len(sentence)==0: # report empty data entry\n",
    "            print(\"no opinion data at entry:\",i)\n",
    "            continue\n",
    "        \n",
    "        merged_df.at[i,'opinion_text'] = clean_sentence(sentence,delete_punc_table,word2index,UNKNOWN_INDEX)\n",
    "    return merged_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_sentence_data_df = clean_all_sentences_in_merged(merged_sentence_data_df,word2index,UNKNOWN_INDEX,verbose=1)\n",
    "merged_sentence_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have processed the opinions into indexes and now we put the opinions into the LSTM or do an average of their embeddings to get vector representation of each opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_embedding(merged_data_df,glove_emb,verbose=0):\n",
    "    # when given all the opinions, in list of index form, this function will convert\n",
    "    # each opinion into a fixed-sized vector representation\n",
    "    starttime = time.time()\n",
    "    \n",
    "    vector_dim = glove_emb.shape[1] # this is likely 300\n",
    "    \n",
    "    n = merged_data_df.shape[0]\n",
    "    embed_list = []\n",
    "    \n",
    "    number_words_in_embed = glove_emb.shape[0] # bigger than this means unknown word (index=400000)\n",
    "    \n",
    "    for i in range(n): # for n opinions\n",
    "        if verbose and i%10000 == 0:\n",
    "            print(i,time.time()-starttime)\n",
    "        \n",
    "        summed_emb = np.zeros(vector_dim)\n",
    "        list_of_indexes = merged_data_df.loc[i,'opinion_text']\n",
    "        m = len(list_of_indexes)\n",
    "        for j in range(m):\n",
    "            \n",
    "            word_index = list_of_indexes[j]\n",
    "            if word_index >= number_words_in_embed: # for this case, if seen unknown word, just ignore\n",
    "                continue\n",
    "            \n",
    "            summed_emb += glove_emb[word_index,:]\n",
    "        if m > 0:\n",
    "            summed_emb /= m\n",
    "        embed_list.append(summed_emb)\n",
    "    return embed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_list = get_average_embedding(merged_sentence_data_df,glove_emb,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we combine the opinion vectors with the merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentence_data_df['opinion_vector'] = 0\n",
    "merged_sentence_data_df['opinion_vector'] = merged_sentence_data_df['opinion_vector'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(merged_sentence_data_df.shape[0]):\n",
    "    merged_sentence_data_df.at[i,'opinion_vector'] = embed_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentence_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_current_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need a mapping from judge id to judge embedding index. Judge id is given in the data, each judge id is unique to one judge, but judge id might not be something clean like 0 to a number.\n",
    "## in our judge embedding, we need to convert judge_id to a index, this index basically indicate in the judge embedding matrix, which vector belongs to which judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_judge_mappings(merged_sentence_data_df,verbose=0):\n",
    "    n = merged_sentence_data_df.shape[0]\n",
    "    index = 0\n",
    "    index2judgeId = {}\n",
    "    judgeId2Index = {}\n",
    "    for i in range(n): # we are not using i as the index because one judge can have multiple cases\n",
    "        if verbose==1 and i%10000==0:\n",
    "            print(i)\n",
    "        \n",
    "        judge_id = int(merged_sentence_data_df.loc[i,'judgeidentificationnumber'])\n",
    "        if judge_id not in judgeId2Index:\n",
    "            index2judgeId[index] = judge_id\n",
    "            judgeId2Index[judge_id] = index\n",
    "            index += 1\n",
    "    return index2judgeId,judgeId2Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index2judgeId,judgeId2Index = get_judge_mappings(merged_sentence_data_df,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(index2judgeId),len(judgeId2Index))\n",
    "number_judges = len(judgeId2Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_judge_mapping(index2judgeId,judgeId2Index,processed_data_path,save_filename):\n",
    "    with open(os.path.join(processed_data_path,save_filename),\"wb\") as f:  \n",
    "        pickle.dump([index2judgeId, judgeId2Index], f)\n",
    "\n",
    "# dump_judge_mapping(index2judgeId,judgeId2Index,processed_data_path,judge_mapping_binary_filename) # run this once\n",
    "        \n",
    "def load_judge_mapping(index2judgeId,judgeId2Index,processed_data_path,save_filename):\n",
    "    with open(os.path.join(processed_data_path,save_filename),\"rb\") as f:  \n",
    "        index2judgeId, judgeId2Index = pickle.load(f) \n",
    "    return index2judgeId, judgeId2Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we also need to put judge embed index into merged data df so it's easier for us to manage training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentence_data_df['judge_embed_index'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(merged_sentence_data_df.shape[0]):\n",
    "    judge_id = int(merged_sentence_data_df.at[i,'judgeidentificationnumber'])\n",
    "    merged_sentence_data_df.at[i,'judge_embed_index'] = judgeId2Index[judge_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentence_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It takes a lot of time to process the data so again we should save the finished data to a binary so that we can easily use later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this once\n",
    "merged_sentence_data_df.to_pickle(os.path.join(processed_data_path,opinion_sum_vector_final_merged_data_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_current_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we should do the train-val-test split, we first sort by judge_id, then for each judge we take a certain ratio of his/her cases and do the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def train_val_test_split(data_df,number_judges,train_ratio=0.8,val_ratio=0.1,verbose=0):\n",
    "    # the input is the processed data\n",
    "    # first we sort it by judge embed index, this might make life easier for the split\n",
    "    # NOTE HERE THE DATA IS NOT SHUFFLED, SO LATER WE NEED TO SHUFFLE EACH DATASET\n",
    "    starttime= time.time()\n",
    "    \n",
    "    sorted_all_data = data_df.sort_values(by='judge_embed_index')\n",
    "    train_df = pd.DataFrame()\n",
    "    val_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame() \n",
    "    for index in range(number_judges):\n",
    "        if verbose and index%10 == 0:\n",
    "            print(index,time.time()-starttime)\n",
    "        \n",
    "        cases_of_this_judge = sorted_all_data.loc[sorted_all_data['judge_embed_index'] == index]\n",
    "        shuffled_cases = shuffle(cases_of_this_judge) # we need it to be shuffled\n",
    "        \n",
    "        num_cases = shuffled_cases.shape[0]\n",
    "        n_of_train = int(num_cases*train_ratio)\n",
    "        n_of_val = int(num_cases*val_ratio)\n",
    "\n",
    "        train_df = train_df.append(shuffled_cases.iloc[:n_of_train,:])\n",
    "        val_df = val_df.append(shuffled_cases.iloc[n_of_train:n_of_train+n_of_val,:])\n",
    "        test_df = test_df.append(shuffled_cases.iloc[n_of_train+n_of_val:,:])\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = train_val_test_split(merged_sentence_data_df,number_judges,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape[0] + val_df.shape[0]+test_df.shape[0],merged_sentence_data_df.shape[0]) # should be the same\n",
    "show_current_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have everything we need to feed into a neural net. For each data entry, we will first concatenate the opinion vector with other things.\n",
    "# But for testing purposes, right now we just use the opinion vector to train judge embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_Tensor(df,feature_dim=300,toshuffle=True):\n",
    "    # use this to convert a dataframe to torch tensor,\n",
    "    # the features are currently opinion vector only\n",
    "    if toshuffle:\n",
    "        df_to_use = shuffle(df)\n",
    "    else:\n",
    "        df_to_use = df\n",
    "    \n",
    "    X = np.zeros((df_to_use.shape[0],feature_dim))\n",
    "    \n",
    "    opinion_vectors = df_to_use['opinion_vector'].as_matrix()\n",
    "    \n",
    "    for i in range(df_to_use.shape[0]):\n",
    "        X[i,:] = opinion_vectors[i]\n",
    "    y = df_to_use['judge_embed_index'].as_matrix()\n",
    "    return FloatTensor(X),LongTensor(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_to_Tensor(train_df)\n",
    "X_val, y_val = df_to_Tensor(val_df)\n",
    "X_test, y_test = df_to_Tensor(test_df)\n",
    "\n",
    "split_vector_sum_data = [X_train,y_train,X_val,y_val,X_test,y_test]\n",
    "\n",
    "def dump_general_data(somedata,processed_data_path,save_filename):\n",
    "    with open(os.path.join(processed_data_path,save_filename),\"wb\") as f:  \n",
    "        pickle.dump(somedata, f)\n",
    "        \n",
    "def load_general_data(processed_data_path,save_filename):\n",
    "    with open(os.path.join(processed_data_path,save_filename),\"rb\") as f:  \n",
    "        return pickle.load(f)\n",
    "        \n",
    "## do this once\n",
    "# dump_general_data(split_vector_sum_data,processed_data_path,opinion_sum_vector_split_6_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_current_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data is fully prepared, in 6 separate tensors, now we need a pytorch dataset and a dataloader for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opinion_sum_vector_split_6_data_filename, 'rb') as pickle_file:\n",
    "    X_train,y_train,X_val,y_val,X_test,y_test = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset = data_utils.TensorDataset(data_tensor=X_train,target_tensor=y_train)\n",
    "train_loader = data_utils.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judge_emb_model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layer_dim, embedding_dim, num_judges):\n",
    "        super(Judge_emb_model,self).__init__()\n",
    "        # input is m x D\n",
    "        self.linear1 = nn.Linear(input_dim,hidden_layer_dim) # D x H \n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.linear2 = nn.Linear(hidden_layer_dim,hidden_layer_dim) # H x H\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.judge_embedding = nn.Linear(hidden_layer_dim,num_judges) # H x J\n",
    "        # the output is m x J\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = F.relu(self.linear1(X))\n",
    "        out = self.dropout1(out)\n",
    "        out = F.relu(self.linear2(out))\n",
    "        out = self.dropout2(out)\n",
    "        out = self.judge_embedding(out)\n",
    "        \n",
    "        # now we have m x J matrix, for m data points, we can do log softmax\n",
    "        log_prob = F.log_softmax(out,dim=1)\n",
    "        return log_prob # for each opinion data, this is probability of which judge writes this opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Judge_emb_model(300,128,300,number_judges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EPOCH = 300\n",
    "TRAIN_SIZE = train_dataset.data_tensor.shape[0]\n",
    "print(TRAIN_SIZE)\n",
    "val_losses = []\n",
    "for i_epoch in range(N_EPOCH):\n",
    "    epoch_train_loss = 0\n",
    "    num_batches_per_epoch = int(TRAIN_SIZE/BATCH_SIZE)\n",
    "    for i_batch,(X_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X_var, y_var = Variable(X_batch),Variable(y_batch)\n",
    "        \n",
    "        y_pred = model.forward(X_var)\n",
    "        loss = criterion(y_pred,y_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "#         if i_batch % 2000 == 0:\n",
    "#             print(i_epoch,i_batch,loss.data[0])\n",
    "        epoch_train_loss += loss.data[0]\n",
    "        \n",
    "    # after each epoch\n",
    "    \n",
    "    X_val_var = Variable(X_val)\n",
    "    y_val_var = Variable(y_val)\n",
    "    model.eval()\n",
    "    y_pred_val = model.forward(X_val_var)\n",
    "    val_loss = criterion(y_pred_val,y_val_var)\n",
    "    print(\"epoch\",i_epoch,\"ave_train_loss\",\n",
    "          epoch_train_loss/num_batches_per_epoch,\"validation loss:\",val_loss.data[0])\n",
    "    val_losses.append(val_loss.data[0])\n",
    "    model.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the validation loss w.r.t. epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(val_losses)),val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
